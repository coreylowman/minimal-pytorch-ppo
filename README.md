# Minimal Pytorch PPO

The intent of this repo is to implement PPO in Pytorch in a minimal amount of code.

## What's included?

- Network Structures
  - [x] MLP Policy
  - [x] LSTM Policy
  - [x] GRU Policy
  - [ ] Conv Policy
- Action Spaces
  - [x] Categorical Action Spaces
  - [ ] Continuous Action Spaces

The code was tested on the `Cartpole-v0` OpenAI Gym Environment.
